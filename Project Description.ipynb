{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Fraudulent Firm Detection\n",
    "\n",
    "### Data Set Information:\n",
    "This dataset is taken from a research explained here. \n",
    "\n",
    "The goal of the research is to help the auditors by building a classification model that can predict the fraudulent firm on the basis of present and historical risk factors. The information about the sectors and the counts of firms are listed respectively as Irrigation (114), Public Health (77), Buildings and Roads (82), Forest (70), Corporate (47), Animal Husbandry (95), Communication (1), Electrical (4), Land (5), Science and Technology (3), Tourism (1), Fisheries (41), Industries (37), Agriculture (200).\n",
    "\n",
    "There are two csv files to present data. Please merge these two datasets into one dataframe. All the steps should be done in Python. Please don't make any changes in csv files. Consider ``Audit_Risk`` as target columns for regression tasks, and ``Risk`` as the target column for classification tasks. \n",
    "\n",
    "### Attribute Information:\n",
    "Many risk factors are examined from various areas like past records of audit office, audit-paras, environmental conditions reports, firm reputation summary, on-going issues report, profit-value records, loss-value records, follow-up reports etc. After in-depth interview with the auditors, important risk factors are evaluated and their probability of existence is calculated from the present and past records.\n",
    "\n",
    "\n",
    "### Relevant Papers:\n",
    "Hooda, Nishtha, Seema Bawa, and Prashant Singh Rana. 'Fraudulent Firm Classification: A Case Study of an External Audit.' Applied Artificial Intelligence 32.1 (2018): 48-64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Task:\n",
    "- Applied the following regression models: KNN repressor, linear regression, Ridge, Lasso, polynomial regression, SVM both simple and with kernels\n",
    "- Used Grid Search to find the best scaling parameter. Plotted graphs to get a better glimpse of the results\n",
    "- Used Cross Validation to find average training and testing score\n",
    "- Found the best regressor and trained the model on the entire dataset using the best parameters and predicted buzz for the test_set\n",
    "\n",
    "### Classification task:\n",
    "- Applied the following classification models: KNN classifcation, Logistic Regression, Linear Supprt Vector Machine, Kerenilzed Support Vector Machine, Decision Tree\n",
    "- Genereated the Confusion Matrix for all the classifiers\n",
    "- Found the best classifier and trained the model on the entire dataset using the best parameters and classified the test_set\n",
    "\n",
    "### Ensemble Learning Techniques:\n",
    "- Improved the model accuracies by 15% by implementing different ensemble learning techniques such as AdaBoost, Bagging, Pasting and Gradient Boosting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
